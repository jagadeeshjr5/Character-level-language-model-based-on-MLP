{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df9da3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import transformers\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "import numpy as np\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bd12057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagad\\AppData\\Local\\Temp\\ipykernel_17968\\1318815340.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x : x.strip() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "Female = pd.read_csv(r'C:\\Names dataset\\Indian-Female-Names.csv')\n",
    "Male = pd.read_csv(r'C:\\Names dataset\\Indian-Male-Names.csv')\n",
    "\n",
    "df = pd.concat([Female, Male], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = df.applymap(lambda x : x.strip() if isinstance(x, str) else x)\n",
    "df.dropna(subset=['name'], inplace=True)\n",
    "\n",
    "df['name'] = df['name'].str.replace('@', '')\n",
    "df['name'] = df['name'].str.replace('.', '')\n",
    "\n",
    "df['name'] = df['name'].str.split('s/o').str[0]\n",
    "df['name'] = df['name'].str.split('d/o').str[0]\n",
    "df['name'] = df['name'].str.split('r/o').str[0]\n",
    "df['name'] = df['name'].str.split('w/o').str[0]\n",
    "df['name'] = df['name'].str.split('c/o').str[0]\n",
    "#df['name'] = df['name'].str.split(' ').str[0]\n",
    "\n",
    "df['name_mod'] = (\n",
    "    df['name'].astype(str) + '.'\n",
    ")\n",
    "\n",
    "words = df['name_mod'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f818236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(list(set(''.join(words))))\n",
    "\n",
    "encode = {s:i for i,s in enumerate(vocab)}\n",
    "\n",
    "decode = {i:s for s,i in encode.items()}\n",
    "\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a52bfe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([238059, 8]) torch.Size([238059])\n",
      "torch.Size([29594, 8]) torch.Size([29594])\n",
      "torch.Size([29631, 8]) torch.Size([29631])\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "def build_dataset(words):  \n",
    "    X, Y = [], []\n",
    "  \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w:\n",
    "            ix = encode[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     \n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte,  Yte  = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4f6242fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embd = 30\n",
    "hidden_dim = 4 * embd\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "n_layers = 4\n",
    "n_epochs = 5 + 5\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "45c21572",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.Y[idx]\n",
    "        return x, y\n",
    "\n",
    "dataset = CustomDataset(Xtr, Ytr)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03bb046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4b265af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.act = torch.nn.GELU(approximate='tanh')\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.ln.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.act(self.bn(self.ln(x)))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2481b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emblayer = nn.Embedding(vocab_size, embd)\n",
    "        \n",
    "        self.ln1 = nn.Linear(embd * block_size, hidden_dim, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.act1 = torch.nn.GELU(approximate='tanh')\n",
    "        \n",
    "        self.FFNblocks = nn.Sequential(*[FFNBlock(hidden_dim) for _ in range(n_layers)])\n",
    "        \n",
    "        self.ln2 = nn.Linear(hidden_dim, vocab_size, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(vocab_size)\n",
    "        self.act2 = torch.nn.GELU(approximate='tanh')\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.ln1.weight)\n",
    "        torch.nn.init.kaiming_normal_(self.ln2.weight)\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        \n",
    "        batch_size, block_size = x.shape\n",
    "        \n",
    "        embeddings = self.emblayer(x)\n",
    "        embeddings = embeddings.view(embeddings.shape[0], -1)\n",
    "        logits = self.act1(self.bn1(self.ln1(embeddings)))\n",
    "        logits = self.FFNblocks(logits)\n",
    "        logits = self.act2(self.bn2(self.ln2(logits)))        \n",
    "        \n",
    "        if y is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def n_parameters(self):\n",
    "\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    @torch.no_grad\n",
    "    def generate(self, n_samples):\n",
    "        \n",
    "        for _ in range(n_samples):\n",
    "            out = []\n",
    "            context = [0] * block_size\n",
    "            logits, loss = self(torch.tensor(context).view(1, -1))\n",
    "            out_probs = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            idx = torch.multinomial(out_probs, num_samples=1, generator=g).item()\n",
    "        \n",
    "            context = context[1:] + [idx]\n",
    "            out.append(idx)\n",
    "            \n",
    "            if idx == 1:\n",
    "                break\n",
    "                \n",
    "            return (''.join(decode[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9e1ab138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91856\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model = LanguageModel()\n",
    "print(model.n_parameters())\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "warmup_lr = transformers.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=n_epochs * len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a71d6c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6574d0bb29d4c30b3f99daad01cef18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614d95156b394ba2a9396c2a41b382f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at epoch 0:  1.5861452\n",
      "Validation Loss at epoch 0:  1.6232734\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29e7b536e7b4b57a4cbcfbfe9e0c0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at epoch 1:  1.4858178\n",
      "Validation Loss at epoch 1:  1.5315468\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166a42b0dd594a38928fe0642eafb29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at epoch 2:  1.4272082\n",
      "Validation Loss at epoch 2:  1.486963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72378dc8ee304e3b9afa68fe0e7eace1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at epoch 3:  1.3873935\n",
      "Validation Loss at epoch 3:  1.4603183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07aa14e05ea42cb899a6d1b38385ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at epoch 4:  1.3483722\n",
      "Validation Loss at epoch 4:  1.4330293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc4117d1a4e415ba98d85746775712c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at epoch 5:  1.3211188\n",
      "Validation Loss at epoch 5:  1.415827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c081934ba34fecaafaec18775f6427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at epoch 6:  1.2985774\n",
      "Validation Loss at epoch 6:  1.4024539\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc76a1d27b5467abaa6f7394b496fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at epoch 7:  1.2836396\n",
      "Validation Loss at epoch 7:  1.3953862\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8adc25bc8a843ca82beae4f9d8da64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at epoch 8:  1.275153\n",
      "Validation Loss at epoch 8:  1.3917046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde8671b77b94a04a9be8856fd07cf89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at epoch 9:  1.2751048\n",
      "Validation Loss at epoch 9:  1.3932405\n",
      "CPU times: total: 34min 35s\n",
      "Wall time: 5min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for _, (X, y) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        logits, loss = model(X, y)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        warmup_lr.step()\n",
    "    model.eval()\n",
    "    print(f\"Training Loss at epoch {epoch}: \", split_loss('train'))\n",
    "    print(f\"Validation Loss at epoch {epoch}: \", split_loss('val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "804b7b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooja\n",
      "laxmi shregar\n",
      "suman devi\n",
      "ram khatun\n",
      "jyoti\n",
      "renu\n",
      "sony sharma\n",
      "sanjay kumar\n",
      "radhika maloge\n",
      "sangeeta\n",
      "subhaj kumar\n",
      "reshma ram\n",
      "heena\n",
      "ranarayan meena\n",
      "puja\n",
      "sunny baira\n",
      "omparkash\n",
      "rawav kuyar\n",
      "ramesh chand\n",
      "rajkao\n",
      "archana\n",
      "gulu ram\n",
      "pinki hhawaraj\n",
      "payak\n",
      "altesh pandey kumar\n",
      "kumag\n",
      "shahna\n",
      "komal\n",
      "neha\n",
      "narender kumar\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for _ in range(30):\n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        logits, loss = model(torch.tensor(context).view(1, -1))\n",
    "        out_probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        idx = torch.multinomial(out_probs, num_samples=1, generator=g).item()\n",
    "\n",
    "        context = context[1:] + [idx]\n",
    "        out.append(idx)\n",
    "\n",
    "        if idx == 1:\n",
    "            break\n",
    "\n",
    "    print(''.join(decode[i] for i in out).strip('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8ff07702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2750894\n",
      "1.3933704\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "    x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "    \n",
    "    dataset = CustomDataset(x, y)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    losses = []\n",
    "    for X, y in data_loader:\n",
    "        logits, loss = model(X)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        losses.append(loss)\n",
    "        \n",
    "    return np.mean(losses)\n",
    "        \n",
    "\n",
    "# put layers into eval mode\n",
    "for layer in model.children():\n",
    "    layer.training = False\n",
    "print(split_loss('train'))\n",
    "print(split_loss('val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30825efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "940b29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"C:\\Character level language model\\model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2ea7d7-6f76-4959-8486-484ed4d39f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ade0b4-560c-4d9d-be18-1dd39e524715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29203db8-fc77-4da5-8459-2e3dd7c8c6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
